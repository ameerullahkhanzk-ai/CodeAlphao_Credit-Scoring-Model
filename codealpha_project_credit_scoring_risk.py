# -*- coding: utf-8 -*-
"""codealpha_Project_Credit Scoring Risk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gDgQAMJ9GS3IKVkAPqnC4LfphK9UgN6B

**Import Some libraries:**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""**Read the  Dataset**"""

# Step 2: Load the dataset
df = pd.read_csv('/content/credit_risk_dataset.csv')
df.head()

"""**Checking the Type of Features and Shape of dataset and columns name:**"""

# Step 3: Basic understanding
print("Shape of dataset:", df.shape)
print("Columns:", df.columns)
df.info()

"""**Checking the Statistical View:**"""

df.describe()

"""**Checking the Missing Values:**"""

df.isnull().sum()

"""**Remove the Missing Values by using dropna methos:**"""

# Step 4: Handle missing values (if any)
# Drop or fill missing values depending on situation
df = df.dropna()  # Simple approach for now
df

"""**Now dataset is cleared from by missing values:**"""

df.isnull().sum()

"""**Use of Label of encoder for encoding:**"""

# Step 5: Encode categorical variables
le = LabelEncoder()

df['person_home_ownership'] = le.fit_transform(df['person_home_ownership'])
df['loan_intent'] = le.fit_transform(df['loan_intent'])
df['loan_grade'] = le.fit_transform(df['loan_grade'])
df['cb_person_default_on_file'] = le.fit_transform(df['cb_person_default_on_file'])
df.head()

"""**Separate the Features and Label columns:**"""

# Step 6: Define features and target
X = df.drop(['loan_status'], axis=1)  # All columns except target
y = df['loan_status']  # Target column

"""**Split the data into training and testing:**"""

# Step 7: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Apply the logistic Model:**"""

# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
lr_preds = lr.predict(X_test)
lr_preds

"""**Apply the Decision Tree Model:**"""

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
dt_preds = dt.predict(X_test)
dt_preds

"""**Apply the Random forest Model:**"""

# Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
rf_preds = rf.predict(X_test)
rf_preds

"""**Evaluate Models**"""

def evaluate_model(name, y_test, y_pred):
    print(f"\n{name} Evaluation:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

evaluate_model("Logistic Regression", y_test, lr_preds)
evaluate_model("Decision Tree", y_test, dt_preds)
evaluate_model("Random Forest", y_test, rf_preds)

"""**ROC-AUC Curve**"""

# Plot ROC Curve for all models
lr_probs = lr.predict_proba(X_test)[:, 1]
dt_probs = dt.predict_proba(X_test)[:, 1]
rf_probs = rf.predict_proba(X_test)[:, 1]

lr_auc = roc_auc_score(y_test, lr_probs)
dt_auc = roc_auc_score(y_test, dt_probs)
rf_auc = roc_auc_score(y_test, rf_probs)

print(f"Logistic Regression AUC: {lr_auc}")
print(f"Decision Tree AUC: {dt_auc}")
print(f"Random Forest AUC: {rf_auc}")

# Plot ROC
fpr1, tpr1, _ = roc_curve(y_test, lr_probs)
fpr2, tpr2, _ = roc_curve(y_test, dt_probs)
fpr3, tpr3, _ = roc_curve(y_test, rf_probs)

plt.plot(fpr1, tpr1, label='Logistic Regression')
plt.plot(fpr2, tpr2, label='Decision Tree')
plt.plot(fpr3, tpr3, label='Random Forest')
plt.plot([0,1],[0,1],'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""**Final Model Selection**"""

# Example: Use Random Forest for final prediction
final_model = rf
new_prediction = final_model.predict(X_test[:5])  # Predict first 5 test cases
print("Predictions:", new_prediction)